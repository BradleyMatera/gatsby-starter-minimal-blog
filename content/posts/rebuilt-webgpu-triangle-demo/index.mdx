---
title: "Why I Rebuilt My WebGPU Triangle Demo (With AI Holding My Hand)"
date: "2025-11-14"
slug: "/rebuilt-webgpu-triangle-demo"
tags: ["webgpu", "webdev", "learning", "webgl"]
description: "An honest rebuild of a tiny WebGPU triangle lab: mostly AI scaffolding, me wiring the pieces, all in the name of learning—not low-level wizardry."
theme: "Low-Level Experiments"
---

> **Honesty:** I’m not a low-level graphics engineer. I leaned on AI for most of the scaffolding and wiring, then I glued the pieces together to understand what was happening. This rebuild is about learning, not mastery.

I built (really, rebuilt) my Triangle Demo because I wanted a clean WebGPU study lab that matched how I learn. I was poking around Three.js first, realized I didn’t grasp the pipeline, and asked AI to scaffold a WebGPU triangle/cube example. The original sample I forked was solid, but I wanted something even smaller and focused on “hello triangle” and “textured cube” fundamentals.

So instead of trying to bend something bigger into a study tool, I pared it down with AI’s help and kept only the parts I could mentally follow.

## Why I needed my own structure

Once I started exploring WebGPU, I realized I learn best when everything in a project is understandable by me (even if AI drafted it) and matches what I’m trying to study. I needed:

- a minimal layout  
- no extra abstraction layers  
- short TypeScript files I could read in one sitting  
- a UI shell I understood  
- a direct mapping from code to canvas

Not because anything else was wrong, but because I wanted a space where every file existed for one reason — to help me understand the pipeline. AI provided the starter, I pruned and annotated until it clicked.

## Building it clean

I rebuilt the demo using tools I already use daily, plus AI to fill gaps:

- **Next.js 16** for the UI  
- **NextUI** for the layout  
- **Bun** for scripts and static exports  
- a single `/lib/webgpu` folder that holds the render loop logic  
- compact TypeScript files for the triangle and cube demos  
- simple WGSL shaders with no extra complexity

AI drafted the initialization steps; I rewrote/annotated them so I could follow along:

1. request the adapter  
2. request the device  
3. configure the canvas  
4. create buffers  
5. load WGSL  
6. submit draws

With everything written by me from scratch, I could finally see exactly how each piece of the pipeline fits together.

## What the rebuild gave me

This rebuild wasn’t about flexing low-level skills. It was about **clarity**.

The new setup gives me:

- a WebGPU project I fully understand  
- a clean space to tweak shaders  
- a simple path to experiment with buffers, attributes, and color outputs  
- direct connection between the code and what I see on the canvas  
- a predictable structure I can keep expanding as I learn

Instead of navigating around a larger ecosystem with its own goals, I now have a focused lab designed specifically for learning WebGPU fundamentals. That alone made the rebuild worth it, even if AI supplied half the code.

## What I learned

Rebuilding (and annotating AI output) taught me more than I expected:

- how the adapter/device negotiation really works  
- how pipelines, buffers, and shaders interact  
- how the render loop lives and breathes  
- how small changes in WGSL show up instantly on the canvas  
- how much easier learning is when the project matches your learning style

This project is not an engine. Not a framework. Not a competitor to anything. It is just a compact, AI-assisted study lab that helps me understand the basics without distractions.

## Final thoughts

The new Triangle Demo is clean, simple, and built around learning—not expertise. It keeps the triangle and the textured cube close at hand so I can focus on the WebGPU pipeline instead of pretending to be a graphics wizard.

It’s the version that finally made WebGPU feel less mysterious, and it gives me a foundation to keep experimenting (with AI guardrails) as the API evolves.
