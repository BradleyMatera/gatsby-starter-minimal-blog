---
title: "Getting Hands-On with Docker Multilang: Hello Worlds and Breaking Stuff"
date: "2024-07-15"
tags: ["Projects", "Docker", "Node.js", "Python", "Learning"]
description: "What I learned about containers by packaging Python and Node.js services, comparing them, and intentionally breaking things inside Docker Compose."
---

## Introduction

Docker made sense to me only after I packaged real services and watched them fail safely. This project started as a class assignment and turned into a playground for learning how containers isolate applications, handle dependencies, and recover from mistakes. I built two services—a Python script and a Node.js Express app—then orchestrated them with Docker Compose to compare behaviours, break them deliberately, and observe what Docker does under the hood.

## Containers vs. Virtual Machines (Quick Primer)

Docker packages an application, its runtime, and its dependencies into a standard unit called a container. Containers share the host kernel and run isolated processes, which makes them lighter than full virtual machines that emulate hardware [1][2]. Understanding that distinction helped me see why containers start quickly and why you can run many on a single host.

## Project Structure

```
docker_multilang_project/
├── docker-compose.yml
├── python-service/
│   ├── Dockerfile
│   └── hello.py
└── node-service/
    ├── Dockerfile
    └── app.js
```

- **Python service:** Prints a greeting and exposes a small math function when run interactively.  
- **Node.js service:** Provides an HTTP endpoint at `/` returning a JSON payload so I can hit it from the browser or curl.  
- **docker-compose.yml:** Starts both containers, maps ports, and creates a dedicated network so I can test communication between services.

### Python Service

```dockerfile
# python-service/Dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY hello.py .
CMD ["python", "hello.py"]
```

`hello.py` prints output to stdout and performs a simple loop so I can see logs stream when the container runs.

### Node.js Service

```dockerfile
# node-service/Dockerfile
FROM node:20-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install --production
COPY app.js .
EXPOSE 3000
CMD ["node", "app.js"]
```

`app.js` uses Express to respond with JSON and logs any errors to stderr so Docker captures them.

### Docker Compose File

```yaml
version: "3.9"
services:
  python:
    build: ./python-service
    container_name: python-service
  node:
    build: ./node-service
    container_name: node-service
    ports:
      - "3000:3000"
```

Running `docker compose up --build` starts both services; visiting `http://localhost:3000` returns the Node.js greeting while the Python logs appear in the terminal.

## Experiments and Learning Moments

1. **Breaking dependencies:** I removed `express` from `package.json` and rebuilt. Docker failed during `npm install`, and the error appeared in the build logs without affecting the Python service. Lesson: containers isolate failures; one service crashing doesn’t bring down the rest of the stack.  
2. **Comparing language behaviours:** I implemented the same counter in Python and Node.js. Python’s loop printed synchronously, while Node.js handled asynchronous requests at the same time. Observing both logs side-by-side clarified differences in runtime models.  
3. **Persistent state experiments:** I attached a volume to the Python service to store a log file, then removed the volume to see how container restarts affect state. It reinforced that containers are ephemeral unless you explicitly mount storage.

## Real-World Use Cases I Spotted

- **Polyglot applications:** Fitness platforms (e.g., Johnson Health Tech products) often mix analytics (Python) with real-time APIs (Node.js). Containers help teams work in their preferred language while keeping deployment consistent.  
- **Safe experimentation:** Containers let me try risky changes—like swapping base images or updating dependencies—without polluting the host environment.  
- **Teaching and demos:** Being able to run two services with one `docker compose up` command is ideal for walkthroughs and classroom experiments.

## Commands I Found Useful

- `docker compose up --build` – rebuilds images and starts services after configuration changes.  
- `docker logs node-service` – inspects logs for one container without stopping it.  
- `docker exec -it python-service /bin/bash` – opens a shell inside the container so I can run additional scripts or inspect files.  
- `docker stats` – monitors CPU and memory usage; helpful when I intentionally created loops to stress-test the containers.

## Lessons Learned

1. Containers are lightweight process wrappers, not virtual machines. Knowing that explains the fast startup times and small footprints.  
2. Compose is invaluable for orchestrating polyglot projects. It handles networking, environment variables, and rebuilds with minimal configuration.  
3. Breaking things is educational. By intentionally removing dependencies or adding bugs, I gained intuition about Docker error messages and how to recover quickly.  
4. Documentation matters. I logged every experiment in the repository README so future me (or teammates) can replay the setup.

## Next Steps

- Add automated tests that run inside the containers to validate health before deployment.  
- Use multi-stage builds to reduce image size, especially for the Node.js service.  
- Experiment with Docker Compose profiles to spin up optional services (e.g., a simulated database).  
- Deploy the stack to a remote server or container service to practise production deployment.

## References

[1] Docker Documentation, “What is a Container?,” https://docs.docker.com/get-started/overview/.  
[2] TACC, “Containers vs. Virtual Machines,” https://portal.tacc.utexas.edu/software-containers.
